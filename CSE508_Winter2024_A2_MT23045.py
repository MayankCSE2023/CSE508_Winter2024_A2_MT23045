# -*- coding: utf-8 -*-
"""CSE508_Winter2024_A2_MT23045.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NJj4XAL3NVOmvFeogFUE2Y-VfhHn6dhj
"""

from google.colab import drive
drive.mount('/content/drive')

import os

import os
import pandas as pd
import re
import requests
from io import BytesIO
from PIL import Image, ImageEnhance
import random
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
import pickle
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer

folder_path ='/content/drive/MyDrive/IR dataset/Assignment-2'
os.chdir(folder_path)

# Load CSV data
csv_file_path = 'A2_Data.csv'
df = pd.read_csv(csv_file_path)

# Rename the "Unnamed: 0" column to "ProductID"
df = df.rename(columns={"Unnamed: 0": "ProductID"})
df

# 1. Image Feature Extraction
def basic_image_preprocessing(img):
    img = img.resize((224, 224))  # Assuming 224x224 as the desired size

    if random.choice([True, False]):
        img = img.transpose(Image.FLIP_LEFT_RIGHT)

    enhancer = ImageEnhance.Brightness(img)
    img = enhancer.enhance(random.uniform(0.5, 1.5))

    enhancer = ImageEnhance.Contrast(img)
    img = enhancer.enhance(random.uniform(0.5, 1.5))

    enhancer = ImageEnhance.Color(img)  # Using 'Color' instead of 'Exposure'
    img = enhancer.enhance(random.uniform(0.5, 1.5))

    return img

# 1. Image Feature Extraction
def download_and_preprocess_image(image_url):
    try:
        response = requests.get(image_url)
        img = Image.open(BytesIO(response.content))
        img = basic_image_preprocessing(img)
        return img
    except Exception as e:
        print(f"Error downloading or processing image: {e}")
        return None

def extract_image_features(image_path, model):
    img = basic_image_preprocessing(image_path)
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)
    img_array = preprocess_input(img_array)

    features = model.predict(img_array)

    return features[0]

def normalize_features(features):
    scaler = StandardScaler()
    normalized_features = scaler.fit_transform(features.reshape(1, -1))

    return normalized_features.flatten()

# Load pre-trained ResNet50 model
resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')

import pickle

# Extract image features
image_features = []
for image_urls in df['Image']:
    img_url = eval(image_urls)[0] if pd.notnull(image_urls) else None

    if img_url:
        img = download_and_preprocess_image(img_url)
        if img:
            img_features = extract_image_features(img, resnet_model)
            normalized_features = normalize_features(img_features)
            image_features.append(normalized_features)
        else:
            # Handle the case when the image cannot be downloaded or processed
            image_features.append(None)
    else:
        # Handle the case when there is no image URL
        image_features.append(None)

# Save the extracted image features using pickle
with open('image_features.pkl', 'wb') as f:
    pickle.dump(image_features, f)

import nltk
import re
import string
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer

# Download NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

def preprocess_text(text):
    if isinstance(text, str):  # Check if the value is a string
        # Lower-Casing
        text = text.lower()

        # Remove ellipses ("...") and words with apostrophes attached ("'m", "'ve", etc.)
        text = re.sub(r'\.\.\.', '', text)
        text = re.sub(r'\s*\'[a-z]*\s*', ' ', text)

        # Tokenization
        tokens = nltk.word_tokenize(text)

        # Remove stopwords and punctuation
        stop_words = set(stopwords.words('english'))
        tokens = [token for token in tokens if token not in stop_words and token not in string.punctuation]

        # Remove blank space tokens
        tokens = [token for token in tokens if token.strip() != '']

        # Stemming
        stemmer = PorterStemmer()
        tokens = [stemmer.stem(word) for word in tokens]

        # Lemmatization
        lemmatizer = WordNetLemmatizer()
        tokens = [lemmatizer.lemmatize(word) for word in tokens]

        return tokens
    else:
        return []  # Return an empty list for non-string values

# Apply pre-processing to the 'Review Text' column
df['ProcessedReviewText'] = df['Review Text'].apply(preprocess_text)

# Display the DataFrame with the processed text
print(df[['ProductID', 'ProcessedReviewText']].head())

df

from sklearn.feature_extraction.text import TfidfVectorizer

# Join the tokenized words back into sentences
df['ProcessedReviewText'] = df['ProcessedReviewText'].apply(lambda x: ' '.join(x))

# Calculate TF-IDF scores
tfidf_vectorizer = TfidfVectorizer()
tfidf_matrix = tfidf_vectorizer.fit_transform(df['ProcessedReviewText'])

# Convert TF-IDF matrix to DataFrame
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())

# Display the DataFrame with TF-IDF scores
print(tfidf_df.head())

# Assuming tfidf_df is your DataFrame
if (tfidf_df != 0).any().any():
    print("There are non-zero values in the DataFrame.")
    non_zero_values = tfidf_df[tfidf_df != 0].stack()
    print("Non-zero values:")
    print(non_zero_values)
else:
    print("All values in the DataFrame are zero.")

# Save the extracted image features using pickle
image_features_path = os.path.join(folder_path, 'image_features.pkl')
with open(image_features_path, 'wb') as f:
    pickle.dump(image_features, f)

# Save the TF-IDF scores using pickle
tfidf_scores_path = os.path.join(folder_path, 'tfidf_scores.pkl')
with open(tfidf_scores_path, 'wb') as f:
    pickle.dump(tfidf_df, f)

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import pickle

# Assuming you have extracted image features in 'image_features' and TF-IDF scores in 'tfidf_df'
# You also need the input image features ('input_image_features') and input review TF-IDF scores ('input_tfidf_scores')

# a. Image Retrieval
def find_most_similar_images(input_image_features, all_image_features, top_k=3):
    # Filter out missing or null values from all_image_features
    valid_image_features = [features for features in all_image_features if features is not None]

    # Check if valid_image_features is empty
    if not valid_image_features:
        print("Error: All image features are missing or null.")
        return None, None

    similarities = cosine_similarity([input_image_features], valid_image_features)[0]
    top_indices = np.argsort(similarities)[::-1][:top_k]
    return top_indices, similarities[top_indices]

# Find the most similar reviews based on TF-IDF scores
def find_most_similar_reviews(input_tfidf_scores, all_tfidf_scores, top_k=3):
    # Filter out missing or null values from all_tfidf_scores
    valid_tfidf_scores = [scores for scores in all_tfidf_scores if scores is not None]

    # Check if valid_tfidf_scores is empty
    if not valid_tfidf_scores:
        print("Error: All TF-IDF scores are missing or null.")
        return None, None

    similarities = cosine_similarity(input_tfidf_scores, valid_tfidf_scores)[0]
    top_indices = np.argsort(similarities)[::-1][:top_k]
    return top_indices, similarities[top_indices]

# Placeholder for image and review URLs
input_image_url = 'https://images-na.ssl-images-amazon.com/images/I/61JYQr9MDbL._SY88.jpg'
input_review = "No Gimmit, I am NOVICE and the Vox is great!!!!,.."

# Download and preprocess the input image
input_image = download_and_preprocess_image(input_image_url)

# Extract features for the input image using the pre-trained ResNet50 model
input_image_features = extract_image_features(input_image, vgg_model)

# Normalize the features
normalized_input_features = normalize_features(input_image_features)

# Display or use the features as needed
print("Features for the input image:")
print(normalized_input_features)

normalized_input_features.size

image_features[0].size

# Preprocess the input review text
preprocessed_input_review = preprocess_text(input_review)

# Display or use the preprocessed input review as needed
print("Preprocessed Input Review:")
print(preprocessed_input_review)

# Calculate TF-IDF scores for the preprocessed input review
input_tfidf_scores = tfidf_vectorizer.transform([' '.join(preprocessed_input_review)]).toarray()

# Find the most similar images based on image features
top_image_indices, image_similarities = find_most_similar_images(normalized_input_features, image_features, top_k=3)

# Display the output
print("—--------------------------------------------------------------------------------------------")
print("USING IMAGE RETRIEVAL")

for i, idx in enumerate(top_image_indices, 1):
    image_url = eval(df.loc[idx, 'Image'])[0]
    review_text = df.loc[idx, 'Review Text']

    # Cosine similarity of images
    image_cosine_similarity = cosine_similarity([normalized_input_features], [image_features[idx]])[0][0]

    # Cosine similarity of text
    text_cosine_similarity = cosine_similarity([input_tfidf_scores.flatten()], [tfidf_df.values[idx]])[0][0]

    # Composite similarity score
    composite_similarity = (image_cosine_similarity + text_cosine_similarity) / 2

    # Display the results
    print(f"{i}) Image URL: {image_url}")
    print(f"   Review: {review_text}")
    print(f"   Cosine similarity of images: {image_cosine_similarity:.4f}")
    print(f"   Cosine similarity of text: {text_cosine_similarity:.4f}")
    print(f"   Composite similarity score: {composite_similarity:.4f}")
    print("---")

# Find the most similar reviews based on TF-IDF scores
top_review_indices, review_similarities = find_most_similar_reviews(input_tfidf_scores, tfidf_df.values, top_k=3)

# Display the output
print("—--------------------------------------------------------------------------------------------")
print("USING TEXT RETRIEVAL")

for i, idx in enumerate(top_review_indices, 1):
    image_url = eval(df.loc[idx, 'Image'])[0]
    review_text = df.loc[idx, 'Review Text']

    # Cosine similarity of images
    image_cosine_similarity = cosine_similarity([normalized_input_features], [image_features[idx]])[0][0]

    # Cosine similarity of text
    text_cosine_similarity = cosine_similarity([input_tfidf_scores.flatten()], [tfidf_df.values[idx]])[0][0]

    # Composite similarity score
    composite_similarity = (image_cosine_similarity + text_cosine_similarity) / 2

    # Display the results
    print(f"{i}) Image URL: {image_url}")
    print(f"   Review: {review_text}")
    print(f"   Cosine similarity of images: {image_cosine_similarity:.4f}")
    print(f"   Cosine similarity of text: {text_cosine_similarity:.4f}")
    print(f"   Composite similarity score: {composite_similarity:.4f}")
    print("---")

# Calculate composite similarity scores
composite_similarity_scores = (image_similarities + review_similarities) / 2

# Combine indices and scores for ranking
combined_indices = np.concatenate([top_image_indices, top_review_indices])
combined_scores = np.concatenate([image_similarities, review_similarities])

# Rank the pairs based on the composite similarity score
ranked_indices = np.argsort(composite_similarity_scores)[::-1]
sorted_combined_indices = combined_indices[ranked_indices]
sorted_combined_scores = composite_similarity_scores[ranked_indices]

# Display the combined retrieval results
print("—--------------------------------------------------------------------------------------------")
print("COMBINED RETRIEVAL RESULTS")

for i, idx in enumerate(sorted_combined_indices, 1):
    image_url = eval(df.loc[idx, 'Image'])[0]
    review_text = df.loc[idx, 'Review Text']

    # Cosine similarity of images
    image_cosine_similarity = cosine_similarity([normalized_input_features], [image_features[idx]])[0][0]

    # Cosine similarity of text
    text_cosine_similarity = cosine_similarity([input_tfidf_scores.flatten()], [tfidf_df.values[idx]])[0][0]

    # Composite similarity score
    composite_similarity = sorted_combined_scores[i - 1]

    # Display the results
    print(f"{i}) Image URL: {image_url}")
    print(f"   Review: {review_text}")
    print(f"   Cosine similarity of images: {image_cosine_similarity:.4f}")
    print(f"   Cosine similarity of text: {text_cosine_similarity:.4f}")
    print(f"   Composite similarity score: {composite_similarity:.4f}")
    print("---")

